{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80JsJB4V93dw"
   },
   "source": [
    "# **LLM Routing wtih Apigee**\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td style=\"text-align: center\">\n",
    "        <a href=\"https://colab.research.google.com/github/ssvaidyanathan/apigee-samples/blob/main/llm-routing/llm_routing_v1.ipynb\">\n",
    "          <img src=\"images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\\\"><br> Open in Colab\n",
    "        </a>\n",
    "      </td>\n",
    "      <td style=\"text-align: center\">\n",
    "        <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fssvaidyanathan%2Fapigee-samples%2Fmain%2Fllm-routing%2Fllm_routing_v1.ipynb\">\n",
    "          <img width=\"32px\" src=\"images/colab-ent.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "        </a>\n",
    "      </td>    \n",
    "      <td style=\"text-align: center\">\n",
    "        <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/ssvaidyanathan/apigee-samples/main/llm-routing/llm_routing_v1.ipynb\">\n",
    "          <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "        </a>\n",
    "      </td>\n",
    "      <td style=\"text-align: center\">\n",
    "        <a href=\"https://github.com/ssvaidyanathan/apigee-samples/blob/main/llm-routing/llm_routing_v1.ipynb\">\n",
    "          <img src=\"images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "        </a>\n",
    "      </td>\n",
    "</table>\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "# Routing Sample\n",
    "\n",
    "- This is a sample Apigee proxy to demonstrate the routing capabilities of Apigee across different LLM providers. In this sample we will use Google VertexAI and Anthropic as the LLM providers\n",
    "- The framework will easily help onboarding other providers using configurations\n",
    "\n",
    "![architecture](./images/arch.jpg)\n",
    "\n",
    "# Benefits of Routing with Apigee:\n",
    "\n",
    "* **Configuration Driven Routing**: All the routing logic are driven through configuration which makes onboarding very easy\n",
    "* **Security**: Irrespective of the model and providers, Apigee will secure the endpoints and\n",
    "* **Consistency**: Apigee can offer that layer of consistency to work with any LLM SDKs that are being used\n",
    "\n",
    "## Setup\n",
    "\n",
    "Use the following GCP CloudShell tutorial. Follow the instructions to deploy the sample.\n",
    "\n",
    "[![Open in Cloud Shell](https://gstatic.com/cloudssh/images/open-btn.png)](https://ssh.cloud.google.com/cloudshell/open?cloudshell_git_repo=https://github.com/ssvaidyanathan/apigee-samples&cloudshell_git_branch=main&cloudshell_workspace=.&cloudshell_tutorial=llm-routing/docs/cloudshell-tutorial.md)\n",
    "\n",
    "## Test Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIdKcCXZQ6Jr"
   },
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ka1d8c81VTH"
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyPnkqS9Hm5I"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using Vertex AI Workbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q_-3uHjVHmA2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeZIwvv-3NiM"
   },
   "source": [
    "#### Set the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAu0gkLn3bZm"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "APIGEE_HOST=\"[your-apigee-host-domain]\" # @param {type:\"string\"}\n",
    "API_KEY=\"[your-apikey]\" # @param {type:\"string\"}\n",
    "\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    raise ValueError(\"Please set your PROJECT_ID\")\n",
    "if not APIGEE_HOST or APIGEE_HOST == \"[your-apigee-host-domain]\":\n",
    "    raise ValueError(\"Please set your APIGEE_HOST\")\n",
    "if not API_KEY or API_KEY == \"[your-apikey]\":\n",
    "    raise ValueError(\"Please set your API_KEY\")\n",
    "\n",
    "API_ENDPOINT = \"https://\"+APIGEE_HOST+\"/v1/samples/llm-routing\"\n",
    "PROMPT=\"Suggest name for a flower shop\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrECV5DbRW1R"
   },
   "source": [
    "#### Execute the Vertex AI Gemini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SbWIkzoARV_n"
   },
   "outputs": [],
   "source": [
    "# from langchain_google_vertexai import VertexAI\n",
    "\n",
    "# # Initialize the Vertex AI LLM\n",
    "# llm = VertexAI(\n",
    "#       project=PROJECT_ID,\n",
    "#       location=\"us-east1\",\n",
    "#       api_endpoint=API_ENDPOINT,\n",
    "#       api_transport=\"rest\",\n",
    "#       streaming=False,\n",
    "#       credentials=None,\n",
    "#       additional_headers={\"x-apikey\": API_KEY},\n",
    "#       model_name=\"gemini-1.5-flash-001\")\n",
    "\n",
    "# llm.invoke(PROMPT)\n",
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "vertexai.init(\n",
    "      project=PROJECT_ID,\n",
    "      location=\"us-east1\",\n",
    "      api_endpoint=API_ENDPOINT,\n",
    "      api_transport=\"rest\",\n",
    "      credentials=None)\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "response = model.generate_content(PROMPT)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-DOBtdIU16S"
   },
   "source": [
    "#### Execute the Vertex AI Anthropic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gryBGybjU31t"
   },
   "outputs": [],
   "source": [
    "from anthropic import AnthropicVertex\n",
    "\n",
    "# Initialize the Anthropic LLM\n",
    "client = AnthropicVertex(\n",
    "        base_url=API_ENDPOINT+\"/v1\",\n",
    "        project_id=PROJECT_ID,\n",
    "        region=\"us-east5\",\n",
    "        default_headers={\"x-apikey\": API_KEY}\n",
    "        )\n",
    "\n",
    "message = client.messages.create(\n",
    "\n",
    "    model=\"claude-3-5-sonnet-v2@20241022\",\n",
    "    max_tokens=256,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PROMPT,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
